{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Decision Tree Classifier (with Gini impurity)\n",
    "class DecisionTree:\n",
    "    def __init__(self, min_samples_split=2, max_depth=5):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        self.classes = np.unique(y)\n",
    "        y = np.array([np.where(self.classes == label)[0][0] for label in y])\n",
    "        self.tree = self._grow_tree(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = [self._predict(inputs, self.tree) for inputs in X]\n",
    "        return np.array([self.classes[pred] for pred in predictions])\n",
    "\n",
    "    def _gini(self, y):\n",
    "        m = len(y)\n",
    "        return 1.0 - sum((np.sum(y == c) / m) ** 2 for c in np.unique(y))\n",
    "\n",
    "    def _split(self, X, y, idx, thresh):\n",
    "        left_mask = X[:, idx] <= thresh\n",
    "        right_mask = X[:, idx] > thresh\n",
    "        return X[left_mask], X[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        m, n = X.shape\n",
    "        # if number of samples is less than or equal to min_samples_split, return None\n",
    "        if m <= self.min_samples_split:\n",
    "            return None, None\n",
    "\n",
    "        best_gini = 1.0\n",
    "        best_idx, best_thresh = None, None\n",
    "        unique_classes = np.unique(y)\n",
    "        class_count = len(unique_classes)\n",
    "\n",
    "        for idx in range(n):\n",
    "            thresholds, classes = zip(*sorted(zip(X[:, idx], y)))\n",
    "            thresholds = np.array(thresholds, dtype=np.float64)\n",
    "            num_left = [0] * class_count\n",
    "            num_right = [np.sum(classes == c) for c in unique_classes]\n",
    "\n",
    "            for i in range(1, m):\n",
    "                class_idx = np.where(unique_classes == classes[i - 1])[0][0]\n",
    "                num_left[class_idx] += 1\n",
    "                num_right[class_idx] -= 1\n",
    "\n",
    "                gini_left = 1.0 - sum((num_left[x] / i) ** 2 for x in range(class_count))\n",
    "                gini_right = 1.0 - sum((num_right[x] / (m - i)) ** 2 for x in range(class_count))\n",
    "                gini = (i * gini_left + (m - i) * gini_right) / m\n",
    "\n",
    "                if thresholds[i] == thresholds[i - 1]:\n",
    "                    continue\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_idx = idx\n",
    "                    best_thresh = (thresholds[i] + thresholds[i - 1]) / 2\n",
    "        \n",
    "        return best_idx, best_thresh\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        num_samples_per_class = [np.sum(y == i) for i in np.unique(y)]\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "        node = {'predicted_class': predicted_class}\n",
    "\n",
    "        if depth < self.max_depth:\n",
    "            idx, thresh = self._best_split(X, y)\n",
    "            if idx is not None:\n",
    "                indices_left = X[:, idx] <= thresh\n",
    "                X_left, y_left = X[indices_left], y[indices_left]\n",
    "                X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "                node['feature_index'] = idx\n",
    "                node['threshold'] = thresh\n",
    "                node['left'] = self._grow_tree(X_left, y_left, depth + 1)\n",
    "                node['right'] = self._grow_tree(X_right, y_right, depth + 1)\n",
    "        return node\n",
    "\n",
    "    def _predict(self, inputs, tree):\n",
    "        if 'threshold' in tree:\n",
    "            feature_index = tree['feature_index']\n",
    "            if inputs[feature_index] <= tree['threshold']:\n",
    "                return self._predict(inputs, tree['left'])\n",
    "            else:\n",
    "                return self._predict(inputs, tree['right'])\n",
    "        else:\n",
    "            return tree['predicted_class']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressor decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DecisionTreeRegressor:\n",
    "    def __init__(self, min_samples_split=2, max_depth=5):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._grow_tree(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict(inputs, self.tree) for inputs in X])\n",
    "\n",
    "    def _ssr(self, y):\n",
    "        if len(y) == 0:\n",
    "            return 0\n",
    "        mean_y = np.mean(y)\n",
    "        return np.sum((y - mean_y) ** 2)\n",
    "\n",
    "    def _split(self, X, y, idx, thresh):\n",
    "        left_mask = X[:, idx] <= thresh\n",
    "        right_mask = X[:, idx] > thresh\n",
    "        return X[left_mask], X[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        m, n = X.shape\n",
    "        if m <= self.min_samples_split:\n",
    "            return None, None\n",
    "\n",
    "        best_ssr = np.inf\n",
    "        best_idx, best_thresh = None, None\n",
    "\n",
    "        for idx in range(n):\n",
    "            thresholds, values = zip(*sorted(zip(X[:, idx], y)))\n",
    "            for i in range(1, m):\n",
    "                y_left, y_right = values[:i], values[i:]\n",
    "                ssr_left, ssr_right = self._ssr(y_left), self._ssr(y_right)\n",
    "                ssr = ssr_left + ssr_right\n",
    "\n",
    "                if thresholds[i] == thresholds[i - 1]:\n",
    "                    continue\n",
    "                if ssr < best_ssr:\n",
    "                    best_ssr = ssr\n",
    "                    best_idx = idx\n",
    "                    best_thresh = (thresholds[i] + thresholds[i - 1]) / 2\n",
    "\n",
    "        return best_idx, best_thresh\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        if len(y) == 0:\n",
    "            return None\n",
    "        predicted_value = np.mean(y)\n",
    "        node = {'predicted_value': predicted_value}\n",
    "\n",
    "        if depth < self.max_depth:\n",
    "            idx, thresh = self._best_split(X, y)\n",
    "            if idx is not None:\n",
    "                indices_left = X[:, idx] <= thresh\n",
    "                X_left, y_left = X[indices_left], y[indices_left]\n",
    "                X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "                node['feature_index'] = idx\n",
    "                node['threshold'] = thresh\n",
    "                node['left'] = self._grow_tree(X_left, y_left, depth + 1)\n",
    "                node['right'] = self._grow_tree(X_right, y_right, depth + 1)\n",
    "        return node\n",
    "\n",
    "    def _predict(self, inputs, tree):\n",
    "        if 'threshold' in tree:\n",
    "            feature_index = tree['feature_index']\n",
    "            if inputs[feature_index] <= tree['threshold']:\n",
    "                return self._predict(inputs, tree['left'])\n",
    "            else:\n",
    "                return self._predict(inputs, tree['right'])\n",
    "        else:\n",
    "            return tree['predicted_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# from Models.ClassifierDT import DecisionTree\n",
    "\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n_trees=100, max_depth=5, min_samples_split=2, n_features=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.n_features = n_features\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        n_samples, n_features = X.shape\n",
    "        self.n_features = self.n_features or n_features\n",
    "        print(\"Fitting Random Forest\")\n",
    "        # add tqdm to show progress bar\n",
    "        tree_range = tqdm(range(self.n_trees))\n",
    "        for _ in tree_range:\n",
    "            tree_range.set_description(f\"Fitting Tree {_ + 1}\")\n",
    "            idxs = np.random.choice(n_samples, n_samples, replace=True)\n",
    "            tree = DecisionTree(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
    "            tree.fit(X[idxs], y[idxs])\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return np.array([np.bincount(tree_preds[:, i]).argmax() for i in range(tree_preds.shape[1])])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest imputation for missing values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Imputation function\n",
    "def random_forest_impute(data, categorical_columns, n_trees=100, max_depth=5, min_samples_split=2, n_features=None, max_iter=10, tol=1e-3):\n",
    "    data_imputed = data.copy()\n",
    "    missing_mask = data.isnull()\n",
    "    n_features = n_features or data.shape[1]\n",
    "    \n",
    "    # Temporarily fill NaNs with a placeholder value\n",
    "    placeholder = \"missing\"\n",
    "    data_imputed[categorical_columns] = data_imputed[categorical_columns].fillna(placeholder)\n",
    "    \n",
    "    # One-hot encode categorical variables, without creating separate column for NaN\n",
    "    data_imputed = pd.get_dummies(data_imputed, columns=categorical_columns, dummy_na=False)\n",
    "        \n",
    "    for iteration in range(max_iter):\n",
    "        print(f\"Iteration {iteration + 1}/{max_iter}\")\n",
    "        prev_data = data_imputed.copy()\n",
    "        categorical_columns = tqdm(categorical_columns)\n",
    "        for column in categorical_columns:\n",
    "            categorical_columns.set_description(f\"Imputing column: {column}\")\n",
    "            # Identify the one-hot encoded columns for the current categorical column\n",
    "            cat_columns = [col for col in data_imputed.columns if col.startswith(column + '_')]\n",
    "            \n",
    "            for cat_column in cat_columns:\n",
    "                # Extract the original column name (without the one-hot suffix)\n",
    "                original_column = cat_column.split('_')[0]\n",
    "                \n",
    "                # Handle the placeholder column separately\n",
    "                if cat_column.endswith('_' + placeholder):\n",
    "                    cat_column_name = original_column + '_missing'\n",
    "                    missing_idx = data_imputed[cat_column_name]\n",
    "                else:\n",
    "                    cat_column_name = cat_column\n",
    "                    missing_idx = data_imputed[cat_column_name].isnull()\n",
    "                \n",
    "                if missing_idx.any():\n",
    "                    print(f\"    Training RandomForest for {cat_column_name}...\")\n",
    "                    # Prepare training data\n",
    "                    X_train = data_imputed[~missing_idx].drop(columns=cat_columns)\n",
    "                    y_train = data_imputed[~missing_idx][cat_column_name]\n",
    "                    \n",
    "                    # Prepare data for imputation\n",
    "                    X_impute = data_imputed[missing_idx].drop(columns=cat_columns)\n",
    "                    \n",
    "                    # Train Random Forest\n",
    "                    rf = RandomForest(n_trees=n_trees, max_depth=max_depth, min_samples_split=min_samples_split, n_features=n_features)\n",
    "                    rf.fit(X_train.values, y_train.values)\n",
    "                    \n",
    "                    # Predict missing values\n",
    "                    data_imputed.loc[missing_idx, cat_column_name] = rf.predict(X_impute.values)\n",
    "        \n",
    "        # Check for convergence (i.e., no change in imputed values)\n",
    "        change = np.linalg.norm(data_imputed.values - prev_data.values)\n",
    "        print(f\"  Change in data: {change}\")\n",
    "        if change < tol:\n",
    "            print(\"Convergence reached.\")\n",
    "            break\n",
    "\n",
    "    print(\"Reversing one-hot encoding...\")\n",
    "    # Reverse One-Hot Encoding\n",
    "    for column in categorical_columns:\n",
    "        cat_columns = [col for col in data_imputed.columns if col.startswith(column + '_')]\n",
    "        data_imputed[column] = data_imputed[cat_columns].idxmax(axis=1).apply(lambda x: x.split('_')[1])\n",
    "        data_imputed.drop(columns=cat_columns, inplace=True)\n",
    "    \n",
    "    print(\"Imputation completed.\")\n",
    "    return data_imputed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest regressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Random Forest Regressor (with averaging)\n",
    "class RandomForestRegressor(RandomForest):\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        n_samples, n_features = X.shape\n",
    "        self.n_features = self.n_features or n_features\n",
    "        rf_range = tqdm(range(self.n_trees))\n",
    "        for _ in rf_range:\n",
    "            rf_range.set_description(f\"Fitting Tree {_ + 1}\")\n",
    "            idxs = np.random.choice(n_samples, n_samples, replace=True)\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
    "            tree.fit(X[idxs], y[idxs])\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return np.mean(tree_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "class DecisionTreeRegressorOptimized:\n",
    "    def __init__(self, min_samples_split=2, max_depth=5):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._grow_tree(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict(inputs, self.tree) for inputs in X])\n",
    "\n",
    "    def _ssr(self, y):\n",
    "        if len(y) == 0:\n",
    "            return 0\n",
    "        mean_y = np.mean(y)\n",
    "        return np.sum((y - mean_y) ** 2)\n",
    "\n",
    "    def _split(self, X, y, idx, thresh):\n",
    "        left_mask = X[:, idx] <= thresh\n",
    "        right_mask = X[:, idx] > thresh\n",
    "        return X[left_mask], X[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        m, n = X.shape\n",
    "        if m <= self.min_samples_split:\n",
    "            return None, None\n",
    "\n",
    "        best_ssr = np.inf\n",
    "        best_idx, best_thresh = None, None\n",
    "\n",
    "        for idx in range(n):\n",
    "            thresholds, values = zip(*sorted(zip(X[:, idx], y)))\n",
    "            for i in range(1, m):\n",
    "                y_left, y_right = values[:i], values[i:]\n",
    "                ssr_left, ssr_right = self._ssr(y_left), self._ssr(y_right)\n",
    "                ssr = ssr_left + ssr_right\n",
    "\n",
    "                if thresholds[i] == thresholds[i - 1]:\n",
    "                    continue\n",
    "                if ssr < best_ssr:\n",
    "                    best_ssr = ssr\n",
    "                    best_idx = idx\n",
    "                    best_thresh = (thresholds[i] + thresholds[i - 1]) / 2\n",
    "\n",
    "        return best_idx, best_thresh\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        if len(y) == 0:\n",
    "            return None\n",
    "        predicted_value = np.mean(y)\n",
    "        node = {'predicted_value': predicted_value}\n",
    "\n",
    "        if depth < self.max_depth:\n",
    "            idx, thresh = self._best_split(X, y)\n",
    "            if idx is not None:\n",
    "                indices_left = X[:, idx] <= thresh\n",
    "                X_left, y_left = X[indices_left], y[indices_left]\n",
    "                X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "                node['feature_index'] = idx\n",
    "                node['threshold'] = thresh\n",
    "                node['left'] = self._grow_tree(X_left, y_left, depth + 1)\n",
    "                node['right'] = self._grow_tree(X_right, y_right, depth + 1)\n",
    "        return node\n",
    "\n",
    "    def _predict(self, inputs, tree):\n",
    "        if 'threshold' in tree:\n",
    "            feature_index = tree['feature_index']\n",
    "            if inputs[feature_index] <= tree['threshold']:\n",
    "                return self._predict(inputs, tree['left'])\n",
    "            else:\n",
    "                return self._predict(inputs, tree['right'])\n",
    "        else:\n",
    "            return tree['predicted_value']\n",
    "\n",
    "def fit_single_tree(tree_index, X, y, max_depth, min_samples_split, progress_queue):\n",
    "    idxs = np.random.choice(len(X), len(X), replace=True)\n",
    "    tree = DecisionTreeRegressorOptimized(max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "    tree.fit(X[idxs], y[idxs])\n",
    "    progress_queue.put(1)  # Put a progress update in the queue\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "# Define the update_progress function at the module level\n",
    "def update_progress(progress_queue, total):\n",
    "    pbar = tqdm(total=total, desc=\"Fitting Trees\", position=0, leave=True)\n",
    "    while True:\n",
    "        item = progress_queue.get()\n",
    "        if item is None:\n",
    "            break\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "def fit_single_tree(tree_index, X, y, max_depth, min_samples_split, progress_queue):\n",
    "    idxs = np.random.choice(len(X), len(X), replace=True)\n",
    "    tree = DecisionTreeRegressorOptimized(max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "    tree.fit(X[idxs], y[idxs])\n",
    "    progress_queue.put(1)  # Put a progress update in the queue\n",
    "    return tree\n",
    "\n",
    "class RandomForestRegressorParallel:\n",
    "    def __init__(self, n_trees=100, max_depth=5, min_samples_split=2, n_features=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.n_features = n_features\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        n_samples, n_features = X.shape\n",
    "        self.n_features = self.n_features or n_features\n",
    "\n",
    "        manager = multiprocessing.Manager()\n",
    "        progress_queue = manager.Queue()\n",
    "\n",
    "        # Start the progress bar updater process\n",
    "        progress_process = multiprocessing.Process(target=update_progress, args=(progress_queue, self.n_trees))\n",
    "        progress_process.start()\n",
    "\n",
    "        # Fit trees in parallel\n",
    "        self.trees = Parallel(n_jobs=-1)(delayed(fit_single_tree)(i, X, y, self.max_depth, self.min_samples_split, progress_queue) for i in range(self.n_trees))\n",
    "        \n",
    "        # Ensure all progress updates are completed\n",
    "        progress_queue.put(None)\n",
    "        progress_process.join()\n",
    "\n",
    "    def predict(self, X):\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return np.mean(tree_preds, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully, starting imputation\n",
      "Starting imputation process...\n",
      "Iteration 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Imputing column: GPU:   0%|          | 0/6 [00:00<?, ?it/s]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training RandomForest for GPU_missing...\n",
      "Fitting Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting Tree 100: 100%|██████████| 100/100 [04:50<00:00,  2.90s/it]\n",
      "Imputing column: GPU-Type:  50%|█████     | 3/6 [04:50<04:50, 96.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training RandomForest for GPU-Type_missing...\n",
      "Fitting Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting Tree 100: 100%|██████████| 100/100 [13:52<00:00,  8.32s/it]\n",
      "Imputing column: Resolution:  67%|██████▋   | 4/6 [18:42<11:07, 333.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training RandomForest for Resolution_missing...\n",
      "Fitting Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting Tree 100: 100%|██████████| 100/100 [12:12<00:00,  7.32s/it]\n",
      "Imputing column: Condition: 100%|██████████| 6/6 [30:54<00:00, 309.07s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Change in data: 31.11269837220809\n",
      "Iteration 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Imputing column: Condition: 100%|██████████| 6/6 [00:00<00:00, 583.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Change in data: 0.0\n",
      "Convergence reached.\n",
      "Reversing one-hot encoding...\n",
      "Imputation completed.\n",
      "Data imputed successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(221,\n",
       " b'2.0.0 closing connection ffacd0b85a97d-360750ad0b7sm4440157f8f.53 - gsmtp')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary libraries and modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from Models.ClassifierDT import DecisionTree\n",
    "# from Models.RegressionDT import DecisionTreeRegressor\n",
    "# from Models.RandomForest import RandomForest\n",
    "# from Models.RandomForestReg import RandomForestRegressor\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "######### Load the dataset\n",
    " \n",
    "# Load the dataset\n",
    "data = pd.read_csv('/Users/edeneldar/Library/Mobile Documents/com~apple~CloudDocs/ML learn.worktrees/origin/mainEden/assignment1/assignment-1-data.csv')\n",
    "\n",
    "# Rename the columns for easier access\n",
    "data = data[['Brand', 'Screen_Size', 'RAM', 'Processor', 'GPU', 'GPU_Type', 'Resolution', 'Condition', 'Price']]\n",
    "\n",
    "# Rename the columns for easier access\n",
    "data.columns = ['Brand', 'Screen-Size', 'RAM', 'Processor', 'GPU', 'GPU-Type', 'Resolution', 'Condition', 'Price']\n",
    "\n",
    "# Specify the categorical columns\n",
    "categorical_columns = ['Brand', 'Processor', 'GPU', 'GPU-Type', 'Resolution', 'Condition']\n",
    "\n",
    "print(\"Data loaded successfully, starting imputation\")\n",
    "\n",
    "# Impute missing values using Random Forest\n",
    "imputed_data = random_forest_impute(data, categorical_columns, n_trees=100, max_depth=5, min_samples_split=2, n_features=None, max_iter=10, tol=1e-3)\n",
    "\n",
    "print(\"Data imputed successfully\")\n",
    "\n",
    "imputed_data.to_csv('/tmp/imputed_data.csv', index=False)\n",
    "\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.base import MIMEBase\n",
    "\n",
    "from email import encoders\n",
    "\n",
    "# send the csv file to the email\n",
    "fromaddr = \"edenstream988@gmail.com\"\n",
    "password = \"xvwd qwqs ngev sbmd\"\n",
    "toaddr = \"edenede2@gmail.com\"\n",
    "\n",
    "msg = MIMEMultipart()\n",
    "\n",
    "msg['From'] = fromaddr\n",
    "msg['To'] = toaddr\n",
    "msg['Subject'] = \"Imputed data\"\n",
    "\n",
    "body = \"Imputed data\"\n",
    "\n",
    "msg.attach(MIMEText(body, 'plain'))\n",
    "\n",
    "filename = \"imputed_data.csv\"\n",
    "attachment = open(\"/tmp/imputed_data.csv\", \"rb\")\n",
    "\n",
    "p = MIMEBase('application', 'octet-stream')\n",
    "p.set_payload((attachment).read())\n",
    "encoders.encode_base64(p)\n",
    "p.add_header('Content-Disposition', \"attachment; filename= %s\" % filename)\n",
    "\n",
    "msg.attach(p)\n",
    "\n",
    "s = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "s.starttls()\n",
    "s.login(fromaddr, password)\n",
    "text = msg.as_string()\n",
    "s.sendmail(fromaddr, toaddr, text)\n",
    "s.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data = pd.read_csv('/Users/edeneldar/Downloads/imputed_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Correct the values of the 'Condition' column to 'New' and 'Refurbished'\n",
    "imputed_data['Condition'] = imputed_data['Condition'].apply(lambda x: 'New' if x == 'New' or x == 'Open box' else 'Refurbished')\n",
    "\n",
    "# Convert categorical features to numerical values using one-hot encoding\n",
    "imputed_data = pd.get_dummies(imputed_data, columns=['Brand', 'Processor', 'GPU', 'GPU-Type', 'Resolution'])\n",
    "\n",
    "reg_data = pd.get_dummies(imputed_data, columns=['Condition'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Split the data\n",
    "\n",
    "# Split the data\n",
    "train_data = imputed_data.iloc[0:2058]\n",
    "val_data = imputed_data.iloc[2058:2499]\n",
    "test_data = imputed_data.iloc[2499:2939]\n",
    "\n",
    "# Split the data for regression\n",
    "train_data_reg = reg_data.iloc[0:2058]\n",
    "val_data_reg = reg_data.iloc[2058:2499]\n",
    "test_data_reg = reg_data.iloc[2499:2939]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and target variables\n",
    "X_train_clas = train_data.drop(columns=['Condition'])\n",
    "X_train_reg = train_data_reg.drop(columns=['Price'])\n",
    "y_train_clas = train_data['Condition']\n",
    "y_train_reg = train_data_reg['Price']\n",
    "\n",
    "X_val_clas = val_data.drop(columns=['Condition'])\n",
    "X_val_reg = val_data_reg.drop(columns=['Price'])\n",
    "y_val_clas = val_data['Condition']\n",
    "y_val_reg = val_data_reg['Price']\n",
    "\n",
    "X_test_clas = test_data.drop(columns=['Condition'])\n",
    "X_test_reg = test_data_reg.drop(columns=['Price'])\n",
    "y_test_clas = test_data['Condition']\n",
    "y_test_reg = test_data_reg['Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert string labels to numerical indices for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string labels to numerical indices\n",
    "class_map = {label: idx for idx, label in enumerate(np.unique(y_train_clas))}\n",
    "y_train_clas_numeric = np.array([class_map[label] for label in y_train_clas])\n",
    "y_val_clas_numeric = np.array([class_map[label] for label in y_val_clas])\n",
    "y_test_clas_numeric = np.array([class_map[label] for label in y_test_clas])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7959183673469388\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Decision Tree Classifier with max_depth=5\n",
    "dt_classifier = DecisionTree(max_depth=5)\n",
    "dt_classifier.fit(X_train_clas.values, y_train_clas_numeric)\n",
    "predictions = dt_classifier.predict(X_val_clas.values)\n",
    "accuracy = np.mean(predictions == y_val_clas_numeric)\n",
    "print(f'Validation Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree regressor training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 35579.868631324396\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Decision Tree Regressor with max_depth=5\n",
    "dt_regressor = DecisionTreeRegressor(max_depth=5)\n",
    "\n",
    "# Fit the Decision Tree Regressor to the training data\n",
    "dt_regressor.fit(X_train_reg.values, y_train_reg.values)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "predictions = dt_regressor.predict(X_val_reg.values)\n",
    "\n",
    "# Calculate the mean squared error of the model\n",
    "mse = np.mean((predictions - y_val_reg.values) ** 2)\n",
    "print(f'Validation MSE: {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting Tree 1:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting Tree 100: 100%|██████████| 100/100 [11:47<00:00,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7913832199546486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Random Forest Classifier\n",
    "rf_classifier = RandomForest(n_trees=100, max_depth=5)\n",
    "rf_classifier.fit(X_train_clas.values, y_train_clas_numeric)\n",
    "predictions = rf_classifier.predict(X_val_clas.values)\n",
    "accuracy = np.mean(predictions == y_val_clas_numeric)\n",
    "print(f'Validation Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest regressor training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting Tree 13:  12%|█▏        | 12/100 [35:15<4:18:30, 176.26s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train and evaluate Random Forest Regressor\u001b[39;00m\n\u001b[1;32m      2\u001b[0m rf_regressor \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_trees\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m rf_regressor\u001b[38;5;241m.\u001b[39mfit(X_train_reg\u001b[38;5;241m.\u001b[39mvalues, y_train_reg\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m      4\u001b[0m predictions \u001b[38;5;241m=\u001b[39m rf_regressor\u001b[38;5;241m.\u001b[39mpredict(X_val_reg\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m      5\u001b[0m mse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean((predictions \u001b[38;5;241m-\u001b[39m y_val_reg\u001b[38;5;241m.\u001b[39mvalues) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[42], line 12\u001b[0m, in \u001b[0;36mRandomForestRegressor.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     10\u001b[0m idxs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(n_samples, n_samples, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m tree \u001b[38;5;241m=\u001b[39m DecisionTreeRegressor(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_split)\n\u001b[0;32m---> 12\u001b[0m tree\u001b[38;5;241m.\u001b[39mfit(X[idxs], y[idxs])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrees\u001b[38;5;241m.\u001b[39mappend(tree)\n",
      "Cell \u001b[0;32mIn[57], line 8\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grow_tree(X, y)\n",
      "Cell \u001b[0;32mIn[57], line 55\u001b[0m, in \u001b[0;36mDecisionTreeRegressor._grow_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m     52\u001b[0m node \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_value\u001b[39m\u001b[38;5;124m'\u001b[39m: predicted_value}\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m depth \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth:\n\u001b[0;32m---> 55\u001b[0m     idx, thresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_split(X, y)\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m         indices_left \u001b[38;5;241m=\u001b[39m X[:, idx] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m thresh\n",
      "Cell \u001b[0;32mIn[57], line 36\u001b[0m, in \u001b[0;36mDecisionTreeRegressor._best_split\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, m):\n\u001b[1;32m     35\u001b[0m     y_left, y_right \u001b[38;5;241m=\u001b[39m values[:i], values[i:]\n\u001b[0;32m---> 36\u001b[0m     ssr_left, ssr_right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ssr(y_left), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ssr(y_right)\n\u001b[1;32m     37\u001b[0m     ssr \u001b[38;5;241m=\u001b[39m ssr_left \u001b[38;5;241m+\u001b[39m ssr_right\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m thresholds[i] \u001b[38;5;241m==\u001b[39m thresholds[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]:\n",
      "Cell \u001b[0;32mIn[57], line 17\u001b[0m, in \u001b[0;36mDecisionTreeRegressor._ssr\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     16\u001b[0m mean_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(y)\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum((y \u001b[38;5;241m-\u001b[39m mean_y) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:2172\u001b[0m, in \u001b[0;36m_sum_dispatcher\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2102\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2103\u001b[0m \u001b[38;5;124;03m    Clip (limit) the values in an array.\u001b[39;00m\n\u001b[1;32m   2104\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2167\u001b[0m \n\u001b[1;32m   2168\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m'\u001b[39m, a_min, a_max, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 2172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2173\u001b[0m                     initial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[1;32m   2177\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_sum_dispatcher)\n\u001b[1;32m   2178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2179\u001b[0m         initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train and evaluate Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_trees=100, max_depth=5)\n",
    "rf_regressor.fit(X_train_reg.values, y_train_reg.values)\n",
    "predictions = rf_regressor.predict(X_val_reg.values)\n",
    "mse = np.mean((predictions - y_val_reg.values) ** 2)\n",
    "print(f'Validation MSE: {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn models training and prediction for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Validation Accuracy (Decision Tree Classifier): 0.7959183673469388\n"
     ]
    }
   ],
   "source": [
    "# import the decision tree classifier and regressor \n",
    "from sklearn.tree import DecisionTreeClassifier as skDecisionTreeClassifier, DecisionTreeRegressor as skDecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier as skRandomForestClassifier, RandomForestRegressor as skRandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "# Train and evaluate Decision Tree Classifier with max_depth=5\n",
    "dt_classifier_sk = skDecisionTreeClassifier(max_depth=5)\n",
    "dt_classifier_sk.fit(X_train_clas, y_train_clas)\n",
    "predictions = dt_classifier_sk.predict(X_val_clas)\n",
    "accuracy = accuracy_score(y_val_clas, predictions)\n",
    "print(f'Sklearn Validation Accuracy (Decision Tree Classifier): {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Validation MSE (Decision Tree Regressor): 35579.868631324396\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train and evaluate Decision Tree Regressor with max_depth=5\n",
    "dt_regressor_sk = skDecisionTreeRegressor(max_depth=5)\n",
    "dt_regressor_sk.fit(X_train_reg, y_train_reg)\n",
    "predictions = dt_regressor_sk.predict(X_val_reg)\n",
    "mse = mean_squared_error(y_val_reg, predictions)\n",
    "print(f'Sklearn Validation MSE (Decision Tree Regressor): {mse}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Validation Accuracy (Random Forest Classifier): 0.8321995464852607\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Random Forest Classifier\n",
    "rf_classifier_sk = skRandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "rf_classifier_sk.fit(X_train_clas, y_train_clas)\n",
    "predictions = rf_classifier_sk.predict(X_val_clas)\n",
    "accuracy = accuracy_score(y_val_clas, predictions)\n",
    "print(f'Sklearn Validation Accuracy (Random Forest Classifier): {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Validation MSE (Random Forest Regressor): 33537.37806605704\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train and evaluate Random Forest Regressor\n",
    "rf_regressor_sk = skRandomForestRegressor(n_estimators=100, max_depth=5)\n",
    "rf_regressor_sk.fit(X_train_reg, y_train_reg)\n",
    "predictions = rf_regressor_sk.predict(X_val_reg)\n",
    "mse = mean_squared_error(y_val_reg, predictions)\n",
    "print(f'Sklearn Validation MSE (Random Forest Regressor): {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision trees visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
